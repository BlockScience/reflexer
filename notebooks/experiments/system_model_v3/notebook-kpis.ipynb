{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment KPI Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Process KPIs](#Process-KPIs)\n",
    "* [Sensitivity Analysis](#Sensitivity-Analysis)\n",
    "* [Control Parameter Analysis and Selection](#Control-Parameter-Analysis-and-Selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project root folder, to enable importing project files from subdirectories\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "path = Path().resolve()\n",
    "root_path = str(path).split('notebooks')[0]\n",
    "os.chdir(root_path)\n",
    "\n",
    "# Force reload of project modules, sometimes necessary for Jupyter kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "# import plotly.io as pio\n",
    "#pio.renderers.default = \"png\"\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dataframe display settings\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.system_model_v3.post_process import post_process_results\n",
    "from experiments.system_model_v3.experiment_monte_carlo import SIMULATION_TIMESTEPS, params\n",
    "from radcad.core import generate_parameter_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results = 'experiments/system_model_v3/experiment_monte_carlo/processed_results.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(processed_results, key='results')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kpis = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['target_price', 'liquidation_ratio', 'rescale_target_price']\n",
    "f = lambda x: (x['target_price'] * x['liquidation_ratio']) if x['rescale_target_price'] else x['target_price']\n",
    "df_kpis['target_price_scaled'] = df_kpis[cols].parallel_apply(f, axis=1)\n",
    "df_kpis['target_price_scaled'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stability** threshold of system: defined as the maximum value for relative frequency of simulation runs that are unstable. Unstable is measured as fraction of runs where:\n",
    "  - market price runs to infinity/zero (e.g. upper bound 10xPI; lower bound 0.10xPI if initial price is PI);\n",
    "  - redemption price runs to infinity/zero (e.g. upper bound 10xPI; lower bound 0.10xPI if initial price is PI);\n",
    "  - Uniswap liquidity (RAI reserve) runs to zero;\n",
    "  - CDP position (total ETH collateral) runs to infinity/zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_target_price = df_kpis['target_price'].iloc[0]\n",
    "initial_target_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kpis[['market_price', 'target_price_scaled', 'RAI_balance', 'eth_collateral']].describe([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stability = df_kpis.groupby(['subset'])\n",
    "\n",
    "df_stability = df_stability.agg({\n",
    "    'market_price': ['min', 'max'],\n",
    "    'target_price_scaled': ['min', 'max'],\n",
    "    'RAI_balance': ['min', 'max'],\n",
    "    'eth_collateral': ['min', 'max'],\n",
    "})\n",
    "df_stability.columns = [\n",
    "    'market_price_min', 'market_price_max',\n",
    "    'target_price_min', 'target_price_max',\n",
    "    'RAI_balance_min', 'RAI_balance_max',\n",
    "    'eth_collateral_min', 'eth_collateral_max'\n",
    "]\n",
    "df_stability = df_stability.reset_index()\n",
    "\n",
    "df_stability['stability_market_price'] = df_stability \\\n",
    "    .apply(lambda x: x['market_price_min'] >= 0.1*initial_target_price and x['market_price_max'] <= 10*initial_target_price, axis=1)\n",
    "\n",
    "df_stability['stability_target_price'] = df_stability \\\n",
    "    .apply(lambda x: x['target_price_min'] >= 0.1*initial_target_price and x['target_price_max'] <= 10*initial_target_price, axis=1)\n",
    "\n",
    "# TODO: discuss threshold\n",
    "df_stability['stability_uniswap_liquidity'] = df_stability \\\n",
    "    .apply(lambda x: x['RAI_balance_min'] >= 500e3, axis=1)\n",
    "\n",
    "# TODO: discuss threshold\n",
    "df_stability['stability_cdp_system'] = df_stability \\\n",
    "    .apply(lambda x: x['eth_collateral_min'] >= 20e3, axis=1)\n",
    "\n",
    "df_stability['kpi_stability'] = df_stability \\\n",
    "    .apply(lambda x: ( \\\n",
    "        x.stability_cdp_system == True and \\\n",
    "        x.stability_uniswap_liquidity == True and \\\n",
    "        x.stability_market_price == True and \\\n",
    "        x.stability_target_price == True) \\\n",
    "        , axis=1)\n",
    "\n",
    "df_stability.query('kpi_stability == True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Volatility** threshold of market price: defined as the maximum value for the **standard deviation** computed. Defined relative to ETH price volatility. Definition: ratio of RAI price volatility / ETH price volatility is not to exceed 0.5.\n",
    "  - over simulation period;\n",
    "  - as moving average with 10-day window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volatility_grouped = df_kpis.groupby(['subset'])\n",
    "\n",
    "df_volatility_grouped = df_volatility_grouped.agg({'market_price': ['std'], 'eth_price': ['std']})\n",
    "df_volatility_grouped.columns = ['market_price_std', 'eth_price_std']\n",
    "df_volatility_grouped = df_volatility_grouped.reset_index()\n",
    "\n",
    "df_volatility_grouped['volatility_ratio_simulation'] = \\\n",
    "    df_volatility_grouped[['subset', 'market_price_std', 'eth_price_std']] \\\n",
    "    .apply(lambda x: x['market_price_std'] / x['eth_price_std'], axis=1)\n",
    "\n",
    "df_volatility_grouped['kpi_volatility_simulation'] = df_volatility_grouped.apply(lambda x: x['volatility_ratio_simulation'] <= 0.5, axis=1)\n",
    "\n",
    "df_volatility_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volatility_series = pd.DataFrame()\n",
    "group = df_kpis.groupby(['subset', 'run'])\n",
    "\n",
    "df_volatility_series['market_price_moving_average_std'] = group['market_price'].rolling(24*10, 1).std()\n",
    "df_volatility_series['eth_price_moving_average_std'] = group['eth_price'].rolling(24*10, 1).std()\n",
    "df_volatility_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danlessa was here 2.2s -> 1.2s\n",
    "f = lambda x: x['market_price_moving_average_std'] / x['eth_price_moving_average_std']\n",
    "df_volatility_series['volatility_ratio_window'] = df_volatility_series.parallel_apply(f, axis=1)\n",
    "df_volatility_series.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danlessa was here. 2.8s -> 1.3s\n",
    "f = lambda x: x['volatility_ratio_window'] != x['volatility_ratio_window'] or x['volatility_ratio_window'] <= 0.5\n",
    "df_volatility_series['volatility_window_series'] = df_volatility_series.parallel_apply(f, axis=1)\n",
    "df_volatility_series['volatility_window_mean'] = (df_volatility_series.groupby(['subset'])\n",
    "                                                                           ['volatility_window_series']\n",
    "                                                                          .transform(lambda x: x.mean()))\n",
    "df_volatility_series.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volatility_series['volatility_window_mean'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volatility_series['kpi_volatility_window'] = df_volatility_series.groupby(['subset'])['volatility_window_mean'].transform(lambda x: x > 0.98)\n",
    "df_volatility_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volatility_series.query('kpi_volatility_window == False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volatility_series['kpi_volatility_window'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge KPI dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danlessa was here. 0.2s -> 80ms\n",
    "cols_to_drop = {'volatility_ratio_window',\n",
    "                'volatility_window_series',\n",
    "                'market_price_moving_average_std',\n",
    "                'eth_price_moving_average_std',\n",
    "                'index'}\n",
    "\n",
    "index_cols = ['subset']\n",
    "dfs_to_join = [df_volatility_grouped, df_volatility_series, df_stability]\n",
    "\n",
    "for i, df_to_join in enumerate(dfs_to_join):\n",
    "    _df = df_to_join.reset_index()\n",
    "    remaining_cols = list(set(_df.columns) - cols_to_drop)\n",
    "    _df = (_df.reset_index()\n",
    "              .loc[:, remaining_cols]\n",
    "              .groupby(index_cols)\n",
    "              .first()\n",
    "          )\n",
    "    dfs_to_join[i] = _df\n",
    "\n",
    "\n",
    "df_kpis = (dfs_to_join[0].join(dfs_to_join[1], how='inner')\n",
    "                         .join(dfs_to_join[2], how='inner')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kpis['kpi_volatility'] = df_kpis.apply(lambda x: x['kpi_volatility_simulation'] and x['kpi_volatility_window'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kpis.query('kpi_volatility == False and kpi_stability == False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liquidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Liquidity** threshold of secondary market: defined as the maximum slippage value below which the controller is allowed to operate.\n",
    "* __NB__: Threshold value will be determined by experimental outcomes, e.g. sample mean of the Monte Carlo outcomes of the slippage value when the system becomes unstable. Would like variance/std deviation of the Monte Carlo slippage series to be small (tight estimate), but can report both mean and variance as part of recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_liquidity_threshold = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity = df[['subset', 'run', 'timestep', 'market_slippage']].copy()\n",
    "df_liquidity = pd.merge(df_liquidity, df_kpis, how='inner', on=['subset', 'run'])\n",
    "df_liquidity['market_slippage_abs'] = df_liquidity['market_slippage'].transform(lambda x: abs(x))\n",
    "df_liquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity.query('subset == 0')['market_slippage_abs'].describe([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity['market_slippage_percentile'] = df_liquidity.groupby(['subset'])['market_slippage'].transform(lambda x: x.quantile(.90))\n",
    "df_liquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df_liquidity_failed = df_liquidity.query('kpi_volatility == False and kpi_stability == False')\n",
    "df_liquidity_failed['market_slippage_percentile_mean'] = df_liquidity_failed.groupby(['subset'])['market_slippage_percentile'].transform(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_liquidity_threshold = df_liquidity_failed['market_slippage_percentile_mean'].mean()\n",
    "critical_liquidity_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity_grouped = df_liquidity.groupby(['subset']).mean()\n",
    "df_liquidity_grouped = df_liquidity_grouped.reset_index()\n",
    "df_liquidity_grouped['kpi_liquidity'] = df_liquidity_grouped.apply(lambda x: x['market_slippage_percentile'] <= critical_liquidity_threshold, axis=1)\n",
    "df_liquidity_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity_grouped.to_pickle('experiments/system_model_v3/experiment_monte_carlo/df_liquidity_grouped.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kpis = df_liquidity_grouped[['subset', 'run', 'kpi_stability', 'kpi_volatility', 'kpi_liquidity']]\n",
    "df_kpis = df_kpis.groupby(['subset']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "{round(df_kpis.query('kpi_stability == True and kpi_volatility == True and kpi_liquidity == True').count().iloc[0]*100/df_kpis.count().iloc[0])}% successful KPIs\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save KPI Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kpis.to_pickle('experiments/system_model_v3/experiment_monte_carlo/df_kpis.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kpis = pd.read_pickle('experiments/system_model_v3/experiment_monte_carlo/df_kpis.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitivity = pd.merge(df, df_kpis, on=['run','subset'], how='inner')\n",
    "df_sensitivity = pd.merge(df_sensitivity, df_liquidity_grouped[['run', 'subset', 'volatility_ratio_simulation']], on=['run','subset'], how='inner')\n",
    "df_sensitivity.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitivity = df_sensitivity.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitivity.to_pickle('experiments/system_model_v3/experiment_monte_carlo/df_sensitivity.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_params = [\n",
    "    'ki',\n",
    "    'kp',\n",
    "    'control_period',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cadcad_machine_search.visualizations import kpi_sensitivity_plot\n",
    "\n",
    "goals = {\n",
    "    'low_volatility'  : lambda metrics: metrics['kpi_volatility'].mean(),\n",
    "    'high_stability'  : lambda metrics: metrics['kpi_stability'].mean(),\n",
    "    'liquidity_threshold': lambda metrics: metrics['kpi_liquidity'].mean(),\n",
    "}\n",
    "\n",
    "kpi_sensitivity_plot(df_sensitivity, goals['low_volatility'], control_params)\n",
    "\n",
    "# for scenario in df_sensitivity['controller_enabled'].unique():\n",
    "#     df = df_sensitivity.query(f'controller_enabled == {scenario}')\n",
    "#     for goal in goals:\n",
    "#         kpi_sensitivity_plot(df, goals[goal], control_params)\n",
    "\n",
    "# for scenario in df_sensitivity['liquidity_demand_shock'].unique():\n",
    "#     df = df_sensitivity.query(f'liquidity_demand_shock == {scenario}')\n",
    "#     for goal in goals:\n",
    "#         kpi_sensitivity_plot(df, goals[goal], control_params)\n",
    "\n",
    "# TODO:\n",
    "# for scenario in df_sensitivity['controller_enabled'].unique():\n",
    "#     df = df_sensitivity.query(f'controller_enabled == {scenario}')\n",
    "#     for goal in goals:\n",
    "#         kpi_sensitivity_plot(df, goals[goal], control_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cadcad_machine_search.visualizations import plot_goal_ternary\n",
    "\n",
    "kpis = {\n",
    "    'volatility_simulation'        : lambda df: df['volatility_ratio_simulation'],\n",
    "    'volatility_window_mean'       : lambda df: df['volatility_ratio_window'].mean(),\n",
    "    'market_price_max'             : lambda df: df['market_price'].max(),\n",
    "    'market_price_min'             : lambda df: df['market_price'].min(),\n",
    "    'redemption_price_max'         : lambda df: df['target_price_scaled'].max(),\n",
    "    'redemption_price_min'         : lambda df: df['target_price_scaled'].min(),\n",
    "    'rai_balance_uniswap_min'      : lambda df: df['RAI_balance'].min(),\n",
    "    'cdp_collateral_balance_min'   : lambda df: df['eth_collateral'].min(),\n",
    "    'price_change_percentile_mean' : lambda df: critical_liquidity_threshold\n",
    "}\n",
    "\n",
    "goals = {\n",
    "    'low_volatility' : lambda metrics: -0.5 * ( metrics['volatility_simulation'] +\n",
    "                    metrics['price_change_percentile_mean'] ),\n",
    "    'high_stability'  : lambda metrics: -(1/6) * ( metrics['market_price_max'] + \n",
    "                    1 / metrics['market_price_min'] + metrics['redemption_price_max'] +\n",
    "                    1 / metrics['redemption_price_min'] + 1 / metrics['rai_balance_uniswap_min'] +\n",
    "                    1 / metrics['cdp_collateral_balance_min'] ),\n",
    "    'liquidity'  : lambda metrics: -metrics['price_change_percentile_mean'],\n",
    "    'combined'   : lambda goals: goals[0] + goals[1] + goals[2]\n",
    "}\n",
    "\n",
    "\n",
    "for scenario in df_sensitivity['controller_enabled'].unique():\n",
    "    df = df_sensitivity.query(f'controller_enabled == {scenario}')\n",
    "    plot_goal_ternary(df, kpis, goals, control_params)\n",
    "\n",
    "for scenario in df_sensitivity['liquidity_demand_shock'].unique():\n",
    "    df = df_sensitivity.query(f'liquidity_demand_shock == {scenario}')\n",
    "    plot_goal_ternary(df, kpis, goals, control_params)   \n",
    "\n",
    "# TODO:\n",
    "# for scenario in df_sensitivity['controller_enabled'].unique():\n",
    "#     df = df_sensitivity.query(f'controller_enabled == {scenario}')\n",
    "#     for goal in goals:\n",
    "#         kpi_sensitivity_plot(df, goals[goal], control_params)\n",
    "\n",
    "# TODO: save both for presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Parameter Analysis and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity_grouped = pd.read_pickle('experiments/system_model_v3/experiment_monte_carlo/df_liquidity_grouped.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_liquidity_grouped = pd.read_pickle('experiments/system_model_v3/experiment_monte_carlo/df_liquidity_grouped.pickle')\n",
    "df_sensitivity = pd.read_pickle('experiments/system_model_v3/experiment_monte_carlo/df_sensitivity.pickle')\n",
    "df_analysis = df_sensitivity.groupby(['subset']).mean()\n",
    "\n",
    "keep_cols = df_liquidity_grouped.columns.difference(df_analysis.columns)\n",
    "df_analysis = pd.merge(df_analysis, df_liquidity_grouped[keep_cols], on=['subset'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all runs that passed the KPIs\n",
    "df_analysis = df_analysis.query('kpi_stability == True and kpi_volatility == True and kpi_liquidity == True')\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.to_pickle('experiments/system_model_v3/experiment_monte_carlo/df_analysis.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset KPI Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_params(df, params, set_params):\n",
    "    param_sweep = generate_parameter_sweep(params)\n",
    "    param_sweep = [{param: subset[param] for param in set_params} for subset in param_sweep]\n",
    "    for subset_index in df['subset'].unique():\n",
    "        for (key, value) in param_sweep[subset_index].items():\n",
    "            df.loc[df.eval(f'subset == {subset_index}'), key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_params=[\n",
    "    'ki',\n",
    "    'kp',\n",
    "    'alpha',\n",
    "    'liquidation_ratio',\n",
    "    'controller_enabled',\n",
    "    'control_period',\n",
    "    'liquidity_demand_shock',\n",
    "    'arbitrageur_considers_liquidation_ratio',\n",
    "    'rescale_target_price'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign parameters to subsets\n",
    "map_params(df_analysis, params, set_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subsets where the controller was enabled\n",
    "df_controller_enabled = df_analysis.query('controller_enabled == True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility KPI Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "lambda_volatility_measure = lambda x: -0.5 * (x + critical_liquidity_threshold)\n",
    "df_controller_enabled['kpi_volatility_measure'] = df_controller_enabled['volatility_ratio_simulation'].apply(lambda_volatility_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volatility_measure = df_controller_enabled.groupby(['subset']).agg({\n",
    "    'kpi_volatility_measure': lambda x: x.mean(skipna=True),\n",
    "    'kp': 'first',\n",
    "    'ki': 'first',\n",
    "    'control_period': 'first',\n",
    "}).sort_values(by='kpi_volatility_measure', kind=\"mergesort\", ascending=False)\n",
    "df_volatility_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability KPI Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "lambda_stability_measure = lambda x: -(1/6) * ( x['market_price_max'] + \n",
    "                    1 / x['market_price_min'] + x['target_price_max'] +\n",
    "                    1 / x['target_price_min'] + 1 / x['RAI_balance_min'] +\n",
    "                    1 / x['eth_collateral_min'] )\n",
    "\n",
    "df_analysis['kpi_stability_measure'] = df_controller_enabled.apply(lambda_stability_measure, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stability_measure = df_controller_enabled.groupby(['subset']).agg({\n",
    "    'kpi_stability_measure': lambda x: x.mean(skipna=True),\n",
    "    'kp': 'first',\n",
    "    'ki': 'first',\n",
    "    'alpha': 'first',\n",
    "    'control_period': 'first',\n",
    "}).sort_values(by='kpi_stability_measure', kind=\"mergesort\", ascending=False)\n",
    "df_stability_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liquidity KPI Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity_measure = df_controller_enabled.groupby(['subset']).agg({\n",
    "    'market_slippage_percentile': lambda x: x.mean(skipna=True),\n",
    "    'kp': 'first',\n",
    "    'ki': 'first',\n",
    "    'alpha': 'first',\n",
    "    'control_period': 'first',\n",
    "}).sort_values(by='market_slippage_percentile', kind=\"mergesort\")\n",
    "df_liquidity_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersection of each KPI measure dataframe\n",
    "subset_kpi_indexes = df_stability_measure.index.intersection(df_liquidity_measure.index).intersection(df_volatility_measure.index)\n",
    "subset_kpi_selection = list(subset_kpi_indexes)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_controller_enabled.query('subset == 12 or subset == 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset 4 time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_controller_enabled.query('subset == 4')[['kp', 'ki', 'control_period', 'alpha']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameter_choice = df[df['subset'].isin(subset_kpi_selection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameter_choice.query('subset == 4').plot(x='timestamp', y='market_price', color='run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameter_choice.query('subset == 4').plot(x='timestamp', y=['market_price_twap'], color='run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameter_choice.query('subset == 4').plot(x='timestamp', y=['target_price_scaled'], color='run')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset 12 time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_controller_enabled.query('subset == 12')[['kp', 'ki', 'control_period', 'alpha']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameter_choice.query('subset == 12').plot(x='timestamp', y='market_price', color='run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameter_choice.query('subset == 12').plot(x='timestamp', y=['market_price_twap'], color='run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameter_choice.query('subset == 12').plot(x='timestamp', y=['target_price_scaled'], color='run')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python (Reflexer)",
   "language": "python",
   "name": "python-reflexer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
